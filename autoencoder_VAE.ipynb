{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObxCaZHJu8QsUppEhgyBl5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimdonggyu2008/audio_synthesis/blob/main/autoencoder_VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFhl5CtKVSSK",
        "outputId": "031077da-78ae-4655-a76b-0e6f25036d69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_FOLDER=\"/content/drive/MyDrive/오디오_합성/\""
      ],
      "metadata": {
        "id": "O7uoC27BVWPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/오디오_합성/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4lXpkgIY1Yj",
        "outputId": "7f849297-9297-499f-be0d-6d8a5272db16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/오디오_합성\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yISPyblfmMNk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization, \\\n",
        "    Flatten, Dense, Reshape, Conv2DTranspose, Activation, Lambda\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.compat.v1.disable_eager_execution() #즉시실행 off, 컴파일, 트레인 함수를 직접 생성하기 위함"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class VAE: #인코더 선언\n",
        "  def __init__(self,\n",
        "               input_shape,\n",
        "               conv_filters,\n",
        "               conv_kernels,\n",
        "               conv_strides,\n",
        "               latent_space_dim):\n",
        "    self.input_shape=input_shape #인코더의 필터 갯수를 차례대로 선언, [28, 28, 1]\n",
        "    self.conv_filters=conv_filters #각 레이어의 컨볼루션 필터 크기, [2, 4, 8] = 2*2,4*4,8*8\n",
        "    self.conv_kernels=conv_kernels # 각 레이어의 커널(필터) 크기[3, 5, 3] = 3*3, 5*5, 3*3\n",
        "    self.conv_strides=conv_strides #컨볼루션에 적용된 필터의 이동거리 [1, 2, 2]\n",
        "    self.latent_space_dim=latent_space_dim #특징 공간 차원 수, 2\n",
        "    self.reconstruction_loss_weight=1000\n",
        "\n",
        "    self.encoder=None #인코더는 최초 입력값의 특징을 추출함\n",
        "    self.decoder=None #디코더는 추출된 특징을 활용해서 최초 입력값과 비슷한 결과를 출력함\n",
        "    self.model=None #모델의 생성\n",
        "    #기본 인코더, 디코더, 모델 비활성화\n",
        "\n",
        "    self._num_conv_layers=len(conv_filters)#레이어 갯수\n",
        "    self._shape_before_bottleneck=None\n",
        "    self._model_input=None\n",
        "\n",
        "    self._num_conv_layers=len(conv_filters)\n",
        "    self._shape_before_bottleneck=None\n",
        "    self._model_input=None\n",
        "\n",
        "    self._build()\n",
        "\n",
        "  def summary(self):\n",
        "    self.encoder.summary()\n",
        "    self.decoder.summary()\n",
        "    self.model.summary()\n",
        "\n",
        "  def compile(self,learning_rate=0.0001):#모델 컴파일링\n",
        "    optimizer=Adam(learning_rate=learning_rate)\n",
        "    mse_loss=MeanSquaredError()\n",
        "    self.model.compile(optimizer=optimizer, loss=self._calculate_combined_loss,#컴파일 과정에서 직접 만든 손실함수 사용\n",
        "                       metrics=[self._calculate_reconstruction_loss,#사용 요소 정의\n",
        "                                self._calculate_kl_loss])\n",
        "\n",
        "  def train(self,x_train,batch_size,num_epochs):#학습, 분류가 아니라서 유효 셋이 없음\n",
        "    self.model.fit(x_train,#입력값\n",
        "                   x_train,#출력 예상값, 원래 값과 비슷하게 나오게 유도했으므로 비슷한 값이 나옴\n",
        "                   batch_size=batch_size,\n",
        "                   epochs=num_epochs,\n",
        "                   shuffle=True)\n",
        "\n",
        "  def save(self, save_folder=\".\"):\n",
        "    self._create_folder_if_it_doesnt_exist(save_folder)\n",
        "    self._save_parameters(save_folder)\n",
        "    self._save_weights(save_folder)\n",
        "\n",
        "  def load_weights(self,weights_path):\n",
        "    self.model.load_weights(weights_path)\n",
        "\n",
        "  def reconstruct(self,images):\n",
        "    latent_representations=self.encoder.predict(images)#인코더로 예측시작, 특징공간 추출\n",
        "    reconstructed_images=self.decoder.predict(latent_representations)#해당 특징공간을 활용해서 생성함\n",
        "    return reconstructed_images,latent_representations#특징공간에서 나타난 결괏값 보여줌\n",
        "\n",
        "  @classmethod\n",
        "  def load(cls,save_folder=\".\"):#저장된 파일이 있을 시, 패러미터 파일, 가중치 파일에서 읽어옴\n",
        "    parameters_path=os.path.join(save_folder,\"parameters.pkl\")\n",
        "    with open(parameters_path,\"rb\") as f:\n",
        "      parameters=pickle.load(f)\n",
        "    autoencoder=VAE(*parameters)\n",
        "    weight_path=os.path.join(save_folder,\"weights.h5\")\n",
        "    autoencoder.load_weights(weights_path)\n",
        "    return autoencoder\n",
        "\n",
        "  def _calculate_combined_loss(self,y_target,y_predicted):#각 오류값들 총합\n",
        "    reconstruction_loss=self._calculate_reconstruction_loss(y_target,y_predicted) #새로 생성된 샘플과의 오차\n",
        "    kl_loss=self._calculate_kl_loss(y_target,y_predicted) #새로 생성된 샘플과의 오차 KL 다이버전스\n",
        "    combined_loss=self.reconstruction_loss_weight*reconstruction_loss+kl_loss #총합\n",
        "    return reconstruction_loss\n",
        "\n",
        "  def _calculate_reconstruction_loss(self,y_target,y_predicted):#새로 생성된 값들의 평균 오차값 계산\n",
        "    error=y_target-y_predicted\n",
        "    reconstruction_loss=K.mean(K.square(error),axis=[1,2,3])\n",
        "    return reconstruction_loss\n",
        "\n",
        "  def _calculate_kl_loss(self,y_target,y_predicted):#새로 생성된 값들의 kl 다이버전스 오류값 계산\n",
        "    kl_loss=-0.5*K.sum(1+self.log_varience-K.square(self.mu)-K.exp(self.log_varience),axis=1)\n",
        "    #(1/2)* 총합(1+ 로그공간(분산)-평균^2-분산)\n",
        "    return kl_loss\n",
        "\n",
        "  def _create_folder_if_it_doesnt_exist(self,folder): #파일 없으면 생성\n",
        "    if not os.path.exists(folder):\n",
        "      os.makedirs(folder)\n",
        "\n",
        "  def _save_parameters(self, save_folder): #저장할 패러미터 지정하고 생성\n",
        "    parameters = [\n",
        "            self.input_shape,\n",
        "            self.conv_filters,\n",
        "            self.conv_kernels,\n",
        "            self.conv_strides,\n",
        "            self.latent_space_dim\n",
        "        ]\n",
        "    save_path=os.path.join(save_folder,\"parameters.pkl\")\n",
        "    with open(save_path,\"wb\") as f:\n",
        "      pickle.dump(parameters,f)\n",
        "\n",
        "  def _save_weights(self,save_folder): #저장할 가중치 지정하고 생성\n",
        "    save_path=os.path.join(save_folder,\"weights.h5\")\n",
        "    self.model.save_weights(save_path)\n",
        "\n",
        "  def _build(self):\n",
        "    self._build_encoder()#인코더 생성\n",
        "    self._build_decoder()\n",
        "    self._build_autoencoder()\n",
        "\n",
        "#오토인코더\n",
        "  def _build_autoencoder(self):#오토인코더 생성, 인코더 + 디코더\n",
        "    model_input = self._model_input\n",
        "    model_output = self.decoder(self.encoder(model_input))\n",
        "    self.model = Model(model_input, model_output, name=\"autoencoder\")\n",
        "\n",
        "#디코더\n",
        "  def _build_decoder(self): #디코더 생성, 구성요소 넣음\n",
        "    decoder_input=self._add_decoder_input() #디코더의 입력값\n",
        "    dense_layer=self._add_dense_layer(decoder_input) # 디코더 내의 완전연결층, 생성을 위함\n",
        "    reshape_layer=self._add_reshape_layer(dense_layer) #레이어 크기 재조정(?)\n",
        "    conv_transpose_layers=self._add_conv_transpose_layers(reshape_layer)#전치행렬로 변경\n",
        "    decoder_output=self._add_decoder_output(conv_transpose_layers)# 디코더 생성값 출력\n",
        "    self.decoder=Model(decoder_input,decoder_output,name=\"decoder\")#입력값, 출력값의 형태를 가지고 모델 생성\n",
        "\n",
        "  def _add_decoder_input(self):#입력값, 특징 공간 크기 지정\n",
        "    return Input(shape=self.latent_space_dim,name=\"decoder_input\")#디코더 입력값으로 지정\n",
        "\n",
        "  def _add_dense_layer(self,decoder_input):#생성층 선언\n",
        "    num_neurons=np.prod(self._shape_before_bottleneck)#보틀넥의 연결갯수 지정\n",
        "    dense_layer=Dense(num_neurons,name=\"decoder_dense\")(decoder_input)#\n",
        "    return dense_layer\n",
        "\n",
        "  def _add_reshape_layer(self,dense_layer): #\n",
        "    return Reshape(self._shape_before_bottleneck)(dense_layer)#텐서의 모양을 입력된 크기로 변경\n",
        "\n",
        "  def _add_conv_transpose_layers(self,x):#들어온 모든 값에 대해서 전치행렬화를 시킴\n",
        "    for layer_index in reversed(range(1,self._num_conv_layers)):\n",
        "      x=self._add_conv_transpose_layer(layer_index,x)\n",
        "    return x\n",
        "\n",
        "  def _add_conv_transpose_layer(self,layer_index,x):#컨볼루션 레이어 역순으로 재지정\n",
        "    layer_num=self._num_conv_layers-layer_index # 레이어 순서를 역순으로 재지정\n",
        "    conv_transpose_layer=Conv2DTranspose(#컨볼루션 구조 지정, 역순으로 가져와서 순서대로 넣음\n",
        "        filters=self.conv_filters[layer_index],\n",
        "        kernel_size=self.conv_kernels[layer_index],\n",
        "        strides=self.conv_strides[layer_index],\n",
        "        padding=\"same\",\n",
        "        name=f\"decoder_conv_transpose_layer{layer_num}\"\n",
        "    )\n",
        "    x=conv_transpose_layer(x)#현재 레이어 역순으로 된 걸로 새로저장\n",
        "    x=ReLU(name=f\"decoder_relu_{layer_num}\")(x)#현재 레이어 활성화함수\n",
        "    x=BatchNormalization(name=f\"decoder_bn_{layer_num}\")(x)#현재 레이어 정규화\n",
        "    return x\n",
        "\n",
        "  def _add_decoder_output(self,x):\n",
        "    conv_transpose_layer=Conv2DTranspose(#뒤집힌 컨볼루션 레이어 선언\n",
        "        filters=1,\n",
        "        kernel_size=self.conv_kernels[0],\n",
        "        strides=self.conv_strides[0],\n",
        "        padding=\"same\",\n",
        "        name=f\"decoder_conv_transpose_layer_{self._num_conv_layers}\"\n",
        "    )\n",
        "    x=conv_transpose_layer(x)#현재 레이어 저장\n",
        "    output_layer=Activation(\"sigmoid\",name=\"sigmoid_layer\")(x)#활성화 함수 적용함\n",
        "    return output_layer#출력\n",
        "\n",
        "#인코더\n",
        "  def _build_encoder(self):#인코더 내부 채우기\n",
        "    encoder_input = self._add_encoder_input()#입력값 변환\n",
        "    conv_layers = self._add_conv_layers(encoder_input) #컨볼루션 레이어에 적용\n",
        "    bottleneck = self._add_bottleneck(conv_layers) # 보틀넥 적용\n",
        "    self._model_input = encoder_input #인코더 적용 끝, 모델로 들어갈 최종 입력값\n",
        "    self.encoder = Model(encoder_input, bottleneck, name=\"encoder\")\n",
        "\n",
        "\n",
        "\n",
        "  def _add_encoder_input(self):#인코더 내부의 입력칸 생성\n",
        "    return Input(shape=self.input_shape,name=\"encoder_input\")#입력값 받아서 넣어줌\n",
        "\n",
        "  def _add_conv_layers(self,encoder_input):#\n",
        "\n",
        "    x=encoder_input#인코더 입력창\n",
        "    for layer_index in range(self._num_conv_layers):\n",
        "      x=self._add_conv_layer(layer_index,x)#레이어 갯수만큼 시행\n",
        "    return x\n",
        "\n",
        "  def _add_conv_layer(self,layer_index,x):#x번째, 컨볼루션 레이어 추가\n",
        "\n",
        "    layer_number=layer_index+1#마지막 relu를 위한 레이어 추가로 넣음\n",
        "    conv_layer=Conv2D( #컨볼루션 선언\n",
        "        filters=self.conv_filters[layer_index],#필터 갯수\n",
        "        kernel_size=self.conv_kernels[layer_index],#커널(필터) 크기\n",
        "        strides=self.conv_strides[layer_index],#몇 칸씩 이동할건지\n",
        "        padding=\"same\",#동일 크기 유지\n",
        "        name=f\"encoder_conv_layer_{layer_number}\"#이름 지정\n",
        "    )\n",
        "    x=conv_layer(x)#컨볼루션의 결괏값(?)\n",
        "    x=ReLU(name=f\"encoder_relu_{layer_number}\")(x)#결괏값에 relu적용\n",
        "    x=BatchNormalization(name=f\"encoder_bn_{layer_number}\")(x)# relu적용값에 정규화 적용\n",
        "    return x #결과값 반화\n",
        "  \"\"\"\n",
        "  def sample_point_from_normal_distribution(args):\n",
        "    mu,log_variance=args\n",
        "    epsilon=K.random_normal(shape=K.shape(self.mu),mean=0.,stddev=1.)\n",
        "    sampled_point=mu.K.exp(log_variance/2)*epsilon\n",
        "    return sampled_point\n",
        "\n",
        "  def _add_bottleneck(self,x):#Dense레이어 보틀넥 생성\n",
        "    self._shape_before_bottleneck=K.int_shape(x)[1:]#backend 임포트한 것 적용, 평평하기 이전 데이터들 저장\n",
        "    x=Flatten()(x) #차원 축소\n",
        "    self.mu=Dense(self.latent_space_dim,name=\"mut\")(x)\n",
        "    self.log_variance = Dense(self.latent_space_dim,\n",
        "                                  name=\"log_variance\")(x)\n",
        "    x=Lambda(sample_point_from_normal_distribution,name=\"encoder_output\")([self.mu,self.log_variance])\n",
        "    return x\n",
        "  \"\"\"\n",
        "  def _add_bottleneck(self, x):\n",
        "        \"\"\"Flatten data and add bottleneck with Guassian sampling (Dense\n",
        "        layer).\n",
        "        \"\"\"\n",
        "        self._shape_before_bottleneck = K.int_shape(x)[1:]\n",
        "        x = Flatten()(x)\n",
        "        self.mu = Dense(self.latent_space_dim, name=\"mu\")(x) #주어진 데이터들의 특징벡터 평균값\n",
        "        self.log_variance = Dense(self.latent_space_dim,\n",
        "                                  name=\"log_variance\")(x)# 주어진 데이터들의 특징벡터 로그분산\n",
        "\n",
        "        def sample_point_from_normal_distribution(args): #중간에 함수 선언, 정규 분포 샘플링\n",
        "            mu, log_variance = args\n",
        "            epsilon = K.random_normal(shape=K.shape(self.mu), mean=0.,\n",
        "                                      stddev=1.)\n",
        "            sampled_point = mu + K.exp(log_variance / 2) * epsilon\n",
        "            return sampled_point\n",
        "\n",
        "        x = Lambda(sample_point_from_normal_distribution,\n",
        "                   name=\"encoder_output\")([self.mu, self.log_variance])\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "  autoencoder=VAE(\n",
        "        input_shape=(28,28,1), #입력값\n",
        "        conv_filters=(32, 64, 64, 64),\n",
        "        conv_kernels=(3,3,3,3),\n",
        "        conv_strides=(1,2,2,1),\n",
        "        latent_space_dim=2\n",
        "    )\n",
        "  autoencoder.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvDV9CstmbUx",
        "outputId": "f5a6fb42-aeec-4165-9840-b81d5be36807"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " encoder_input (InputLayer)  [(None, 28, 28, 1)]          0         []                            \n",
            "                                                                                                  \n",
            " encoder_conv_layer_1 (Conv  (None, 28, 28, 32)           320       ['encoder_input[0][0]']       \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " encoder_relu_1 (ReLU)       (None, 28, 28, 32)           0         ['encoder_conv_layer_1[0][0]']\n",
            "                                                                                                  \n",
            " encoder_bn_1 (BatchNormali  (None, 28, 28, 32)           128       ['encoder_relu_1[0][0]']      \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " encoder_conv_layer_2 (Conv  (None, 14, 14, 64)           18496     ['encoder_bn_1[0][0]']        \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " encoder_relu_2 (ReLU)       (None, 14, 14, 64)           0         ['encoder_conv_layer_2[0][0]']\n",
            "                                                                                                  \n",
            " encoder_bn_2 (BatchNormali  (None, 14, 14, 64)           256       ['encoder_relu_2[0][0]']      \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " encoder_conv_layer_3 (Conv  (None, 7, 7, 64)             36928     ['encoder_bn_2[0][0]']        \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " encoder_relu_3 (ReLU)       (None, 7, 7, 64)             0         ['encoder_conv_layer_3[0][0]']\n",
            "                                                                                                  \n",
            " encoder_bn_3 (BatchNormali  (None, 7, 7, 64)             256       ['encoder_relu_3[0][0]']      \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " encoder_conv_layer_4 (Conv  (None, 7, 7, 64)             36928     ['encoder_bn_3[0][0]']        \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " encoder_relu_4 (ReLU)       (None, 7, 7, 64)             0         ['encoder_conv_layer_4[0][0]']\n",
            "                                                                                                  \n",
            " encoder_bn_4 (BatchNormali  (None, 7, 7, 64)             256       ['encoder_relu_4[0][0]']      \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " flatten_6 (Flatten)         (None, 3136)                 0         ['encoder_bn_4[0][0]']        \n",
            "                                                                                                  \n",
            " mu (Dense)                  (None, 2)                    6274      ['flatten_6[0][0]']           \n",
            "                                                                                                  \n",
            " log_variance (Dense)        (None, 2)                    6274      ['flatten_6[0][0]']           \n",
            "                                                                                                  \n",
            " encoder_output (Lambda)     (None, 2)                    0         ['mu[0][0]',                  \n",
            "                                                                     'log_variance[0][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 106116 (414.52 KB)\n",
            "Trainable params: 105668 (412.77 KB)\n",
            "Non-trainable params: 448 (1.75 KB)\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " decoder_input (InputLayer)  [(None, 2)]               0         \n",
            "                                                                 \n",
            " decoder_dense (Dense)       (None, 3136)              9408      \n",
            "                                                                 \n",
            " reshape_3 (Reshape)         (None, 7, 7, 64)          0         \n",
            "                                                                 \n",
            " decoder_conv_transpose_lay  (None, 7, 7, 64)          36928     \n",
            " er1 (Conv2DTranspose)                                           \n",
            "                                                                 \n",
            " decoder_relu_1 (ReLU)       (None, 7, 7, 64)          0         \n",
            "                                                                 \n",
            " decoder_bn_1 (BatchNormali  (None, 7, 7, 64)          256       \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " decoder_conv_transpose_lay  (None, 14, 14, 64)        36928     \n",
            " er2 (Conv2DTranspose)                                           \n",
            "                                                                 \n",
            " decoder_relu_2 (ReLU)       (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " decoder_bn_2 (BatchNormali  (None, 14, 14, 64)        256       \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " decoder_conv_transpose_lay  (None, 28, 28, 64)        36928     \n",
            " er3 (Conv2DTranspose)                                           \n",
            "                                                                 \n",
            " decoder_relu_3 (ReLU)       (None, 28, 28, 64)        0         \n",
            "                                                                 \n",
            " decoder_bn_3 (BatchNormali  (None, 28, 28, 64)        256       \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " decoder_conv_transpose_lay  (None, 28, 28, 1)         577       \n",
            " er_4 (Conv2DTranspose)                                          \n",
            "                                                                 \n",
            " sigmoid_layer (Activation)  (None, 28, 28, 1)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121537 (474.75 KB)\n",
            "Trainable params: 121153 (473.25 KB)\n",
            "Non-trainable params: 384 (1.50 KB)\n",
            "_________________________________________________________________\n",
            "Model: \"autoencoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_input (InputLayer)  [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " encoder (Functional)        (None, 2)                 106116    \n",
            "                                                                 \n",
            " decoder (Functional)        (None, 28, 28, 1)         121537    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 227653 (889.27 KB)\n",
            "Trainable params: 226821 (886.02 KB)\n",
            "Non-trainable params: 832 (3.25 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xwRKpi0WYxPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A1_6zNwYONxp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}